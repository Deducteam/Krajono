% LLNCStmpl.tex
% Template file to use for LLNCS papers prepared in LaTeX
%websites for more information: http://www.springer.com
%http://www.springer.com/lncs

\documentclass{llncs}
%Use this line instead if you want to use running heads (i.e. headers on each page):
%\documentclass[runningheads]{llncs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
\usepackage{multirow}
\usepackage{color}

\begin{document}
\title{A Fast Intepreter for \lp}

%If you're using runningheads you can add an abreviated title for the running head on odd pages using the following
%\titlerunning{abreviated title goes here}
%and an alternative title for the table of contents:
%\toctitle{table of contents title}

%\subtitle{Subtitle Goes Here}

%For a single author
%\author{Author Name}

%For multiple authors:

\author{Cvetan Dunchev$^1$ \and
        Ferruccio Guidi$^1$ \and
        Claudio Sacerdoti Coen$^1$ \and
        Enrico Tassi$^2$}


%If using runnningheads you can abbreviate the author name on even pages:
%\authorrunning{abbreviated author name}
%and you can change the author name in the table of contents
%\tocauthor{enhanced author name}

%For a single institute
\institute{Department of Computer Science,
University of Bologna\\ 
Mura Anteo Zamboni 7, 40127 Bologna, Italy \\
\email{name.surname@unibo.it}
\and INRIA Sophia Antipolis\\ 2004 route des Lucioles - BP 93, 06902 Sophia Antipolis Cedex, France
\email{name.surname@inria.fr}}

% If authors are from different institutes
%\institute{First Institute Name \email{email address} \and Second Institute Name\thanks{Thank you to...} \email{email address}}

%to remove your email just remove '\email{email address}'
% you can also remove the thanks footnote by removing '\thanks{Thank you to...}'

\newcommand{\frag}{Reduction-Free Fragment}
\newcommand{\lp}{$\lambda$Prolog}
\newcommand{\elpi}{ELPI}
\newcommand{\CSC}[1]{\textcolor{red}{#1}}
\newcommand{\FG}[1]{\textcolor{magenta}{#1}}

\maketitle

\begin{abstract}
We present a new interpreter for \lp{} that runs consistently faster than
the bytecode compiled by Teyjus, that is believed to be the best
available implementation for \lp. The key insight is the identification of a fragment of
the language, which we call \frag, that occurs quite naturally in \lp{}
programs and that admits constant time reduction and unification rules.
The implementation exploits De Bruijn levels and no explicit substitutions,
whereas Teyjus is based on De Bruijn indexes and explicit substitutions (the
suspension calculus).
\end{abstract}

\section{Introduction and State of the Art}
\lp{} is a logic programming language based on an intuitionistic fragment
of Church's Simple Theory of Types. An extensive introduction to the language
with examples can be found in~\cite{dalebook}. Teyjus 2.0~\cite{teyjus} is a compiler for \lp{} implemented by the research team of Gopalan Nadathur. It is considered to be the fastest available implementation of the language. Previous slower implementations are described in~\cite{}. \CSC{OTHER IMPLEMENTATIONS IN ISABELLE ETC. MISSING}

The main difference with respect to Prolog is that \lp{} manipulates $\lambda$-tree expressions, i.e. syntax containing binders. Therefore the natural application of \lp{} is metaprogramming (see~\cite{thefrenchguy} for an interesting discussion), including: automatic generation of programs from specifications; animation of operational semantics; implementation of type checking algorithms; program transformations. Via the Curry-Howard isomorphism~\cite{curryhoward}, a type-checker is a proof-checker, the main component of an interactive theorem prover (ITP). Indeed the motivation of our interest in the language is that we are looking for the best programming language to implement an ITP, and we currently believe that an extension of \lp{} with Constraints (\`a la CLP) is the best choice.

\begin{table}
\begin{center}
\begin{tabular}{c@{~~}|@{~~}c}
A type checker for the simply typed $\lambda$-calculus. &
Weak CBN reduction for the $\lambda$-calculus.\\\hline
\begin{minipage}{5.0cm}
\begin{verbatim}
of (app M N) B :-
   of M (impl A B), of N A.
of (lam F) (impl A B) :-
   pi x\ of x A => of (F x) B.

\end{verbatim}
\end{minipage}
&
\begin{minipage}{5.0cm}
\begin{verbatim}
cbn (lam F) (lam F).
cbn (app (lam F) N) M :-
   cbn (F N) M.
cbn (app M N) R :-
   cbn M MM, cbn (app MM N) R.
\end{verbatim}
\end{minipage}
\end{tabular}
\end{center}
\caption{\label{example1} Examples 1 (on the left) and 2 (on the right).}
\end{table}
In Table~\ref{example1} we show a type-checker and a weak CBN evaluator for the
$\lambda$-calculus. The $\lambda$-term $(\lambda x.xx)$ is encoded in
$\lambda$-tree syntax as \verb+(lam (x\ app x x))+ where \verb+x\F+ is
the $\lambda$-abstraction of \lp{}, that binds \verb+x+ in \verb+F+, and
\verb+lam+ is the constructor for object-level abstraction, that builds
a term of type $\mathcal{T}$ from a function of type
$\mathcal{T} \to \mathcal{T}$, with $\mathcal{T}$ the type of representations
of $\lambda$-terms. \verb+app+ takes two terms of type $\mathcal{T}$ and builds
their object-level application of type $\mathcal{T}$.

The first half of the example shows a typical pattern in \lp: in order to analyze a term with binders, one needs to do the recursion under the binder. This is achieved exploiting the forall quantifier \verb+pi x\G+ together with logical
implication \verb+F => G+. Operationally: the forall quantifier declares a new local constant \verb+x+, meant to be fresh, i.e. different from any other name bound in \verb+G+ or in the current program; logical implication temporarily augments the program with the new formula \verb+F+ --- to be understood as a new clause --- that is retracted as soon as the premise goes out of scope. Denotationally, these are just the standard rules for introduction of implication and the universal quantifier.

Looking at the example, the functional term \verb+F+ is applied to \verb+x+, replacing the variable bound in \verb+F+ with the fresh name \verb+x+: \verb+F x+ is therefore the body of our object-level $\lambda$-abstraction after $\alpha$-conversion to \verb+x+ of the bound name. The implication is used to assume \verb+A+ to be the type of \verb+x+, in order to prove that the body of the abstraction has type \verb+B+ and therefore the whole abstraction has type \verb+impl A B+ (i.e. $A \to B$ in standard notation). Note that, unlike in the standard presentation of the typing rules, we do not need to manipulate an explicit context $\Gamma$ to type the free variables. Instead the assumptions of the form \verb+of x A+ are just added to the program clauses, and \lp{} takes care of dropping them from the context when \verb+x+ goes out of scope.

In this first example, the meta-level $\beta$-reduction is only employed in \verb+F x+ to match the body of a $\lambda$-abstraction after $\alpha$-converting the bound variable to a fresh one. In particular, $\beta$-reduction only replaces a name with another name.
The second example shows a radically different pattern: in order to implement object-level substituion --- and thus object-level $\beta$-reduction--- we use the meta-level $\beta$-reduction. For example, if
\verb+F+ is \verb+x\ app x x+, then \verb+F N+ reduces to \verb+app N N+.
Note that in this case $\beta$-reduction is fully general, because it replaces
a name with a term.

The main issue with variables of higher type applied to generic terms is
that they trigger the flexible-flexible and flexible-rigid cases of
higher order unification: for example \verb+F t = pair t t+ has no most general
unifier, and it admits either one or four solutions. While there are implementations~\cite{isabelle?} of \lp{} that enumerate all solutions according to Huet's algorithm~\cite{???}, Teyjus 2.0 behaves differently: all flexible-flexible and flexible-rigid unification problems outside the pattern fragment are postponed until the variable is instantiated. If the computation ends with postponed problems, those are reported to the users as disagreement pairs.

\begin{table}
\begin{center}
\hspace{-1.5cm}
\begin{tabular}{c@{~~}|@{~~}c}
\begin{minipage}{5.0cm}
\begin{verbatim}
cbn (lam F) (lam F).
cbn (app (lam F) N) M :-
   subst F N B, cbn B M.
cbn (app M N) R :-
   cbn M MM, cbn (app MM N) R.

\end{verbatim}
\end{minipage}
&
\begin{minipage}{5.0cm}
\begin{verbatim}
subst F N B :-
   pi x\ copy x N => copy (F x) B.
copy (lam F1) (lam F2) :-
   pi x\ copy x x => copy (F1 x) (F2 x).
copy (app M1 N1) (app M2 N2) :-
   copy M1 M2, copy N1 N2.
\end{verbatim}
\end{minipage}
\end{tabular}
\end{center}
\caption{\label{example3} Example 3: Weak CBN implemented in the pattern fragment.}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{c@{~~}|@{~~}c}
\begin{minipage}{5.0cm}
\begin{verbatim}
forall P [].
forall P [X|XS] :-
   P X, forall P XS.
\end{verbatim}
\end{minipage}
&
\begin{minipage}{5.0cm}
\begin{verbatim}
(pi Y\  Y :- pi x0\ r Y) =>
   (pi x0\ q (x1\ X^0 x0 x1))
\end{verbatim}
\end{minipage}
\end{tabular}
\end{center}
\caption{\label{example4} Example 4 (on the left): an higher order predicate whose definition is not in the pattern fragment. Example 5 (on the right): all clauses are in the \frag, but after two inferences the obtain term is not.}
\end{table}

The pattern fragment, discovered by Dale Miller in~\cite{???}, is a well-behaved fragment of higher-order unification that is stable under \lp{} resolution. I.e. if the syntax of the program is in the fragment, all unification problems will only involve terms that are still in the fragment. Moreover, all unification problems in the pattern fragment admit a most general unifier, even in the flexible-flexible and flexible-rigid case. The fragment is easily defined as follows: a variable \verb+X+ can only be applied to a list of distinct names, and only if those names are not in the scope of \verb+X+.
Example 1 is written in the pattern fragment: \verb+F+ is applied to \verb+x+,
and \verb+F+ is universally quantified before \verb+x+, that therefore is not
in the scope of \verb+F+. Example 2, instead, is not in the fragment because
of \verb+F N+ where \verb+N+ is not a name. However, at the expense of some
verbosity, it is possible to rewrite Example 2 to force it in the pattern
fragment (see Table~\ref{example3}). The definition of higher order predicates
like in Table~\ref{example4}, is, however, typically outside the pattern
fragment.

One important property of the pattern fragment is that $\beta$-reduction can
only substitute names with other names. This property, however, is not
easily exploitable and an implementation still needs to traverse the body
of the abstraction to do the replacing. If we look at Example 1, we see that
in order to type-check a $\lambda$-abstraction the operational semantics
requires to first traverse all the body just to replace a bound name with a
fresh one. This is a major source of inefficiency that is hardly justified.
To cope with it, Teyjus 2.0 invented the \emph{suspension calculus}~\cite{susp1,susp2}, a form of explicit substitution calculus that propagates the substitution lazily (and that works also outside the pattern fragment). Some benchmarks~\cite{susp3} concluded that adopting the suspension calculus provides a significant speedup over a naive implementation of susbtitution. Nevertheless, programs compiled with Teyjus are quite slow and, at least in cases like Example~1, the whole idea of substituting bound names with fresh names, in the spirit of the locally nameless approach~\cite{???}, seems a waste of time.

In~\ref{sec:fragment} we will identify a sub-fragment of the pattern fragment
that we call~\frag. A clever implementation can completely avoid the traversal of the body of the abstraction during $\beta$-reduction, if the term to be reduced is in the~\frag.
In the remaining sections we will present an interpreter
for \lp, written in OCaml and called \elpi{} (Embedded \lp{} Interpreter), that exploits the \frag, and we will compare it to Teyjus on a few benchmarks.
We anticipate that \elpi{} is consistently faster than Teyjus on every test, sometimes up to \CSC{XXXX} times.

\section{The~\frag.}\label{sec:fragment}
The abstract syntax of \lp{} is defined as follow:
$$\begin{array}{l}
   Q ::= \forall x.Q ~|~ P \Rightarrow Q ~|~ Q \wedge Q ~|~ T ~|~ \exists X.Q \\
   P ::= \forall X.P ~|~ Q \Rightarrow P ~|~ P \wedge P ~|~ T\\
   T ::= c ~|~ x ~|~ X ~|~ \lambda x.A ~|~ T~A\\
   A ::= Q ~|~ P
\end{array}$$
where $c,x,X$ range respectively over the set of constants, the set of universally quantified names (also called local constants) and the set of existentially quantified variables. Formulas $Q$ that occur in positive positions are called \emph{queries}. Formulas $P$ that occur in negative position are called \emph{clauses}. The logical atoms are captured by $T$. Note that, the language being
higher order, there is no distinction between formulas and terms, and both queries and clauses can be passed as arguments to predicates. Note also that $\forall$ binds local constants in positive position, and existentially quantified variables in negative position, according to the logical equivalence
$(\forall x.P) \Rightarrow Q \equiv \exists x.(P \Rightarrow Q)$. Disjunction
is definable, but the derivational semantics is complete only if it is used in
positive formulas (like for the existential quantifiers). We let $\mathcal{E}$ range over all syntactic categories above, and we call $\mathcal{E}$ an expression.

The concrete syntax differs from the abstract syntax in a few ways: \verb+pi x\+ and \verb+sigma x\+ are used in place of $\forall x.$ and $\exists x.$; $P \Rightarrow Q$ can be written as \verb+P => Q+ or as \verb+Q :- P+; conjunction is written using commas; $\lambda x.$ is written \verb+x\+. A program is just a list of clauses terminated by dots. All free uppercase names in a clause are implicitly universally quantified around the clause. The user writes a query to be resolved against a program. All free uppercase names in the query are also implicitly existentially quantified. The semantics of the pair program/clause is a new query obtained as the implication between the $n$-ary conjunction of all the clauses and the user provided query.

$\lambda x.A$ and $\forall x.Q$ bind $x$ respectively in $A$ and $Q$;
$\forall X.P$ and $\exists X.Q$ bind $X$ respectively in $P$ and $Q$.
Formulas are identified up to $\alpha$-equality as usual.

\paragraph{Definition and expressivity of the \frag}
The De Bruijn level of a name $x$ in an expression is the number of binders to be crossed when traversing the expression from the root towards the leaves before finding the binder for $x$~\cite{debruijnlevel}. For example, in the following expression every variable $x_i$ has level $i$: $\forall x_0.\exists X^1.\lambda x_1.\lambda x_2. \exists X^3. p~(X^1~x^1) X^3$. Every expression can be
$\alpha$-converted so that every name is renamed to $x_i$ where $i$ is its level. In the rest of the discussion we assume every term to be renamed in this way. Similarly, we can rename every variable $X$ to $X^j$ where $j$ is the smallest number such that $X^j$ has visibility of all names smaller than $j$. In the example above, $X^1$ has visibility only of $x^0$, and $X^3$ has visibility of $\{x^0,x^1,x^2\}$.

An expression is in the \frag{} iff every occurrence of an existentially quantified $X^j$ occurs applied to $x_j \ldots x_{j+k-1}$ for $k >= 0$.

Examples: $X^2~x_2~x_3$ and $X^2$ are in the fragment; $X^2~x_3$ and $X^2~x_3~x_2$ are not.

Observe that Example 1 and 3 in Tables~\ref{example1,example3} are in \frag, and that most occurrences of existentially quantified variables in Example 2 are in \frag{} as well. Every Prolog program is also in \frag. As we will see in~Section~\ref{grundlagen}, a type-checker for a dependently typed language and and evaluator based on a reduction machine are also naturally in \frag, showing that the fragment is already quite expressive.

\paragraph{Computational properties of the \frag}
First of all, observe that the \frag{} is a sub-fragment of the pattern fragment. Therefore an unification problem $X^j~x_j\ldots x_{j+k-1} \equiv \mathcal{E}$ admits a most general unifier.

The most interesting property of the \frag, which also justify its name, is the following. Let $\sigma$ be a \emph{valid} substitution for existentially quantified variables, i.e. such that for every $X^j$ all names $x_i$ occurring in $X^j \sigma$ are s.t. $i < j$. Let $X^j \sigma = \lambda x_j. \ldots \lambda x_{j+n}.\mathcal{E}$. Then
\begin{equation}\label{deffrag}(X^j~x_j \ldots x_{j+k-1}) \sigma
 = \left\{ \begin{array}{ll}
\mathcal{E}~x_{j+n+1} \ldots x_{j+k-1} & \mbox{if $n+1 < k$} \\
\lambda x_{j+k}. \ldots \lambda x_{j+n}.\mathcal{E} & \mbox{otherwise}
      \end{array} \right.\end{equation}

In equation~\ref{deffrag}, the equality is syntactical, i.e. no $\alpha$-conversion of $\mathcal{E}$ is required. Therefore the $\beta$-reductions triggered
by the susbtitution of $X^j$ require constant time and no pass over the term.
Note that, once all $\beta$-redex that occur syntactically in the term are
fired at compile time, or if explicitly written $\beta$-redexes are forbidden,
then every $\beta$-redex in the computation is triggered by the substitution
of an existentially quantified variable. Therefore, if the program is and
remains in the \frag, then all $\beta$-reductions can be implemented in
constant time.

In a similar way, also unification can be implemented very easily observing
that $X^j~x_j\ldots x_{j+k-1}$ can always be rewritten as
$X^{j+k}$ instantiating $X^j$ with $\lambda x_j. \ldots \lambda x_{j+k-1}. X^{j+k}$ for a fresh existentially quantified variable $X^{j+k}$. Therefore every
unification problem in the \frag{} can be reduced in linear time in $k$ to a
problem of the kind $X^{j+k} \equiv \mathcal{E}$, that is immediately solved
by instantiating $X^{j+k}$ with $\mathcal{E}$ if the free names of $E$ are
known to be a subset of $\{x_0,\ldots,x_{j+k-1}\}$.

Finally, another benefit of working with De Bruijn levels is that the
$\forall$-introduction rule can also be implemented in constant time as well
because there is no need to replace the bound variable with a fresh name.
The price to pay is an additional complexity in the backchain rule: when
a clause is selected, the clause needs to be $\alpha$-converted --- lifted
in De Bruijn indexes/levels terminology --- to move it in the current scope.
For example, if the query is \verb+ pi x_0\ r x_0+ and \verb+r X :- pi x_0\ pi x_1\ p x_0 x_1 X+ is a clause, after two inferences the new query becomes
\verb+pi x_1\ pi x_2\ p x_1 x_2 x_0+ because the introduction rule for
\verb+pi+ has already fixed the name \verb+x_0+.

\paragraph{Instability of the \frag}
Unlike the pattern fragment, the \frag{} is unstable for computation.
I.e. there are simple examples where the program and the initial query are
written in the fragment, but during execution we generate terms outside the
fragment (but still in the pattern fragment). This is a consequence of the
need for lifting clauses during backchaining.
Consider example~5 in Table~\ref{example4}.
After two inference steps the term \verb+(x1\ X^0 x0 x1)+, that is in
the fragment and assigned to \verb+Y+, is moved under \verb+pi x0+ becoming
\verb+r (x2\ X^0 x0 x2)+. The latter is no longer in the fragment.

Therefore, and contrarily to what happens with the pattern fragment, an
implementation must handle both terms in the fragment, with their efficient
computation rules, and terms outside the fragment. Our limited experience so
far, however, is that several programs initially written in the fragment
remains in the fragment during computation, or they can be slightly modified
to achieve that property.

\section{\elpi: an Embedded \lp{} Interpreter.}\label{sec:elpi}
The current version of \elpi, together with the benchmarks presented in
the next section, can be downloaded at \CSC{\url{http://xxxxx}}. The intepreter
is entirely written in OCaml and it is \CSC{XXX} lines long. It augments the language presented in the paper with Prolog-style cuts and a few custom predicates for printing. The name is due to the fact that we eventually plan to augment the language with constraints and then embed it in the implementation of interactive theorem provers like Coq, that are often written in OCaml.

We carefully wrote the code so that unrechable terms in \lp{} are encoded by unreachable terms in OCaml. Therefore we inherit garbage collection from the OCaml runtime. The algebraic datatype used to encode terms has different constructors for occurrences of terms in the \frag, and for occurrences outside the fragment. In particular an occurrence $X^j x_j \ldots x_{j+k-1}$ is simply represented as a triple $\langle r,j,k\rangle$ where $r$ is a reference to the term
$X$ is instantiated to, or to a dummy term if $X$ is still unbound. Finally, we carefully cherry picked some design decisions from the WAM, implementing our own variations in several places. The variations have been made necessary to decrease the pressure on the garbage collector of OCaml, that is responsible for a significant percentage of the running time. For example, the heap and the stack are not organized as large arrays of mostly unused cells because otherwise the garbage collector needs to traverse the arrays at every minor and major collection. Similarly, we employ a mix of mutable and persistent data structures, avoiding mutable structures for data that is likely to survive, in order to avoid the penalty of the write barrier on data in the old generation~\cite{???}.
Further details will be reported in a future work due to lack of space.

\section{Benchmarks.}\label{sec:benchmarks}

\input{helena}

In the following table we compare the performance of ELPI and Teyjus over several benchmarks 
devided into 3 groups. 
The first group contains 4 first-order problems taken from the Aquarius suite. The problems 
are the well known logic games such as the crtypto-multiplication, $\mu$-puzzle, 
generalized eight queens problem and the Einstein's zebra puzzle, respectively. The second group contains 
2 higher-order problems within the fragment. The first one generates a long term with nested 
lambdas. Teyjus fails to manipulate terms with nesting factor more than $2^{16}$. The second 
example shows a few applications of the {\bf cbv} function defined above over the 
Church numerals. Here again Teyjus fails. The third group contains a single higher-order 
example from the Teyjus suite. It is outside the fragment. 

\begin{center}

  \begin{tabular}{|p{1.5cm}||c|r||c|r||c|c|}
    \hline
      \multicolumn{1}{|c||}{Test} &
      \multicolumn{2}{|c||}{ELPI} &
      \multicolumn{2}{|c||}{Teyjus} &
      \multicolumn{2}{|c|}{Ratio(ELPI/Teyjus)} \\
    \hline
      &  time     & memory  & time & memory &  time & memory \\
    
      &  \multicolumn{1}{c|}{(s)}  & \multicolumn{1}{c||}{(Kb)} & \multicolumn{1}{c|}{(s)}  & \multicolumn{1}{c||}{(Kb)} & \multicolumn{1}{c|}{(s)}  & \multicolumn{1}{c|}{(Kb)} \\
    \hline
    \hline
    crypt &  3.46 & 25,828  & 6.59 & 18,048 &  0.52 & 1.43 \\
    \hline    
    mu &  1.83 & 5,716 &  3.62 & 50,076 &  0.50 & 0.11 \\
    \hline
    queens &  1.33  & 108,140 &  2.02 & 69,968 &  0.65 & 1.54 \\
    \hline    
    zebra &  0.85 & 6,944 &  1.89 & 8,412 &  0.44 & 0.82 \\
    \hline     
    \hline
    lambda3 &  1.91 & 5,068 &  5.45 & 237,860 &  2.85 & 0.02 \\
    \hline
    reduce &  0.54 & 30,628 &   ... & ...   & ... & ... \\
    \hline
    \hline
    ski &  1.30 & 21,668 &  2.68 & 8,896  & 0.48 & 2.43 \\
    \hline
    
  \end{tabular}

 \end{center}



 
 
\bibliographystyle{plain}
\bibliography{reference}

\end{document} 
