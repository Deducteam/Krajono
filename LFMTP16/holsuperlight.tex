%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% numbers       To obtain numeric citation style instead of author/year.

\usepackage{amsmath}
\usepackage{fancyvrb}

\newcommand{\cL}{{\cal L}}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{LFMTP '16}{June 23, 2016, Porto, Portugal}
\copyrightyear{2016}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

% Uncomment the publication rights you want to use.
%\publicationrights{transferred}
%\publicationrights{licensed}     % this is the default
%\publicationrights{author-pays}

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{A lightweight implementation of an HOL system in an extension of higher order logic programming}   % 'preprint' option specified.

\title{Implementing HOL in an Higher Order Logic Programming Language}
%\subtitle{Subtitle Text, if any}

\authorinfo{Cvetan Dunchev \and Claudio Sacerdoti Coen}
           {University of Bologna}
           {cdunchev@hotmail.com/claudio.sacerdoticoen@unibo.it}
\authorinfo{Enrico Tassi}
           {INRIA Sophia-Antipolis}
           {enrico.tassi@inria.fr}

\maketitle

\begin{abstract}
We present a proof-of-concept prototype of a (constructive variant of an) HOL interactive theorem prover written a Higher Order Logic Programming (HOLP) language, namely an extension of LambdaProlog. The prototype is meant to support the claim, that we reinforce, that HOLP is the class of languages that provides the right abstraction level and programming primitives to obtain concise implementations of theorem provers. We identify and advocate for a programming technique, that we call semi-shallow embedding, while at the same time identifying the reasons why pure LambdaProlog is not sufficient to support that technique, and it needs to be extended.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore,
% you may leave them out
%\terms
%term1, term2

\keywords
lambdaProlog, HOL, Higher Order Logic Programming, Constraints

\section{Introduction}
What are the programming paradigm and the programming languages better suited for the implementation of interactive theorem provers? Better suited here means providing high level primitives at the good level of abstraction, relieving the programmer from the burden of (re)implementing the basic mechanisms a theorem prover relies on.

Every (interactive) theorem prover:
\begin{enumerate}
\item Has to manipulate expressions with binders up to $\alpha$-conversion, and it needs to implement substitution. Binders are ubiqutous: they occur in formulae, but also in both procedural and declarative scripts (new hypotheses are named and have an associated scope), and in proof objects as well.
\item Has to implement automatic proof search, either in the small or in the large, that requires to explore the search space with backtracking. Because the search space can be very large, the programmer needs way to control backtracking and direct the exploration.
\item Has to manipulate incomplete data structures, i.e. data structures having parts not specified yet. Moreover, invariants have to be enforced on the data structures and lazily checked when the data structures get instantiated. Examples of incomplete data occurs in formulae (omission of types to be inferred), sequents (omission of terms to be identified later, e.g. writing $X$ for a yet unknown witness of an existential statement), and proof objects (an incomplete proof has a proof object containing an hole).
\end{enumerate}

The three features discussed above also interact in complex ways. For example, renaming bound variables in a term that contains metavariables (i.e. omitted sub-terms) must record the renaming as an explicit substitution applied to the metavariable to resume the renaming when the metavariable will be istantiated. Or, backtracking must be aware of dependencies between subgoals due to sharing of metavariables in order to split the subgoals into independent clusters of goals such that once a cluster is solved it becomes useless to backtrack that solution because it won't affect the search space of the other goals.

In a series of papers from the XXs \cite{????}, Amy Felty already advocated Higher Order Logic Programming (HOLP) as the programming paradigm best suited for the three tasks above. LambdaProlog, the flagship of HOLP languages, manipulates syntax with binders, relieving the programmer from problems due to renaming and substitution; being a logic language it has backtracking for free; it allows to control backtracking via the usual Prolog's cut ("!") whose semantics and pragmatics is well known, even if it does not fit completely well the logical reading of the language; finally the language uses metavariables that range over both data and functions, and the complex implementation of LambdaProlog takes care of all interactions between binders ($\lambda$-abstraction) and metavariables, in particular addressing the problem of higher-order unification under mixed prefixes~\cite{??}.

Despite the push by Amy Felty, none of the interactive theorem provers in use is implemented in HOLP. With the exception of Mizar, implemented in Pascal for historical reasons, and the new Lean system, implemented in C++ for efficienty, all other systems (Coq, Isabelle, Agda, Matita, etc. \cite{?17thproversoftheworld??}) are implemented in either Haskell or an ML variant.

In general, functional languages provide a good compromise between performance and high-level coding, and algebraic data types can naturally encode syntax without binders. In particular, ML was born as the language for implementing the LCF theorem prover, one of the first theorem provers of the world. Nevertheless, these languages solve none of the three problems above:
\begin{enumerate}
\item with the exception of FreshML, that has also not been used for interactive theorem proving yet, functional languages do not abstract the details about binders and the user must encode bound variables via De Brujin indexes (like in Coq and Matita) or it must implement $\alpha$-conversion and substitution carefully (like in HOL Light). De Brujin indexes allow the code to be very efficient, but code that handles them is very error prone.
\item the ML and Haskell families do not provide backtracking for free. A limited form of backtracking can be implemented in ML via exceptions: an exception can be raised to backtrack to a previous state, but once a function call is over it is not possible to backtrack into it any longer. Continuations based monads to implement backtracking (plus state to handle metavariables and failure) exists~\cite{?????}, but the code is quite complicated and it has efficiency problems unless it is manually optimized (Section~X of~\cite{????}).
\item managing metavariables, their interaction with binders and higher order unification of fragments of it requires a lot of fragile and complex code (e.g. $\approx$ 3100 lines of OCaml code for Matita, compared to the $\approx$ 1500 lines for the kernel that implements $\beta$-reduction, conversion and the inference rules of the logic).
\end{enumerate}

The situation described above is bad in two respects.
\begin{enumerate}
\item All the code that deals with the three problems is essentially logic-independent, but it requires to be re-implemented when ones wants to experiment with a new logic or implement a new system. With the exception of the monad cited above, it also seems hard to encapsulate the boilerplate code into a reusable library: a real extension of the programming language is necessary.
\item The code of the systems becomes very low-level, having to deal with all kind of intricacies due to binders and metavariables. Therefore it is hard for external programmers to contribute to the code base, for example to implement new domain specific tactics. The result is that these systems often implement in user space a second programming language, exposed to the user to write tactics, that takes care of binding, metavariables, backtracking and its control. For example, LTac~\cite{???} is such a programming language for Coq, that also sports several other mini-languages to let the user customize the behaviour of the system (e.g. to declare type classes~\cite{???}, used to provide unification hints~\cite{???}). Not only the system becomes more complex because of the need to provide and interpret a new programming language on top, but its semantics is problematic: the beaviour of the system becomes the combination of pieces of code written in multiple languages and interacting in non trivial ways. Static analysis of this kind of code is out of reach.
\end{enumerate}

Adopting an HOLP language seems a promising idea. First of all the boilerplate code is pushed once and for all in the interpreter of the language, becoming decoupled from the programming logic of the theorem prover. Therefore the code of the theorem prover becomes much more clean, and very close to the inference rules it implements. Secondly, because of the decoupling, it becomes possible to experiment with alternative implementations of the HOLP language, e.g. susbtituting De Brujin levels for the indexes (like in~\cite{???}) or profiling the implementation of the language on different applications. Thirdly, and most importantly, there is no more any need for ad-hoc languages in user space: the users that want can directly contribute to the code base of the theorem proving ignoring all the gory details.

Nevertheless, as we said, no system has been implemented in LambdaProlog, despite the interest raised by the work of Felty (her XXX paper~\cite{???} has more than YYY citations). One reason is due to performance: logic languages are hard to optimize, and LambdaProlog is orders of magnitudes harder than Prolog not only because of binders and higher order unification, but also because it is higher order (one can pass predicates around) and it allows a primitive (logical implication $P => Q$) to temporarily augment the code of the program (with $P$, while proving $Q$) in a lexically scoped way, making some well known Prolog static analyses and optimizations hard. Moreover, LambdaProlog had for some time only very slow implementations, until Teyjus was born~\cite{???} after the work of Felty. Recent work by the authors also showed that the performances of Teyjus are not so good~\cite{???}, considering that Teyjus compiles the code to an extension of the Warren abstract machine instruction set, while the ELPI interpreter of the authors that attempts no compilation is able to run consistently faster than Teyjus (Section XXX of~\cite{???}).

In this paper we push seriously the idea of implementing in the ELPI variant of LambdaProlog an interactive theorem prover, inspired by HOL Light, but for a constructive variant of the logic. The aim of the experiment is to come up with implementation guidelines, that differ from the ones of Amy Felty, and to quantify what is the loss in term of performance w.r.t. systems implemented in functional languages.

We also note that our expertise acquired with the implementation of Matita was put to full already in the implementation of our ELPI interpreter. Indeed, we essentially had to split out the code of Matita that deals with the three problems above, and figure out how to integrate it in an interpreter for a logic language. In the long term, we would like to scale the HOL experiment to a new implementation of Matita/Coq (or at least its logical core, that excludes the user interface).

Interestingly enough, the methodology we identified, presented in Section~\ref{UUU}, requires significant extensions of LambdaProlog, that we implemented in ELPI and that we briefly describe here as well.

As a final remark, the interest of the work, that is still on-going, is not to obtain a new competitive implementation of HOL, that would require several men years and could be of limited interest. In particular, we only developed the system so far to the point where all the parts of a typical theorem prover implementation for HOL are represented to judge the feasibility and economy of the implementation.

Section~\ref{????} \ldots

\section{LambdaProlog in a nutshell}
LambdaProlog extends the core of Prolog in two directions.
\begin{enumerate}
\item it allows in the syntax $lambda$-abstractions (written \texttt{x \ p} for $\lambda x.p$), applications (written \texttt{p q} like in $\lambda$-calculus and unlike in Prolog) and metavariables both in argument and in head position (e.g. \texttt{iter [X|XS] F [Y|YS] :- F X Y, iter XS F YS.} where the metavariable $F$ is to be istantiated with a binary predicate like \texttt{(x \ y \ y = x+x)})
\item it generalizes Horne clauses to Hereditarily XXXX clauses, whose grammar is
$$PUT HERE THE GRAMMAR$$
\end{enumerate}

The semantics of the connectives that occurs in Hereditarily XXX clauses is given by the introduction and elimination rules of the connectives in higher order logic. In particular:
\begin{itemize}
\item \texttt{p => q} assumes \texttt{p}, that is turned into a new program clause, to prove \texttt{q}
\item \texttt{pi x \ q} (universal quantification) introduces a new fresh variable \texttt{y} and proves \texttt{q} after replacing \texttt{y} with \texttt{c}
\item \texttt{sigma x \ q} (existential quantification) introduces a new metavariable \texttt{X}and proves \texttt{q} after replacing \texttt{x} with \texttt{X}. Later \texttt{X} can be istantiated with any term whose free variables were all in scope at the time \texttt{sigma} was processed
\item assuming \texttt{p,q} means assuming both \texttt{p} and \texttt{q} independently
\item assuming \texttt{pi x \ q} means assuming all possible instances of \texttt{q}, i.e. all use of the clause will substitute \texttt{x} in \texttt{q} with a fresh metavariable \texttt{X}
\item assuming \texttt{sigma x \ q} means generating a new fresh constant \texttt{y} and assuming \texttt{q} after replacing \texttt{x} with \texttt{y}
\end{itemize}

\texttt{sigma} in clause positions are not in ``standard'' LambdaProlog and they are accepted by our ELPI interpreter, but not from Teyjus. However, Teyjus implements a module system~\cite{???} that allows to declare variables local to the list $k_1,\ldots, k_n$ of clauses of the module. The same behaviour can be obtained in ELPI with (\texttt{sigma x \ k}$_1$, \ldots, \texttt{k}$_n$). Declaring local constants is the only and fundamental mechanism in LambdaProlog to restrict the trusted code base.

The other major difference between the ELPI version of LambdaProlog and the ``official'' one of Teyjus is that we do not enforce any type discipline, nor we try to statically enforce the restriction to Hereditarily XXX. Errors at run-time (e.g. invoking a list as predicate) result in abortion of the program execution. On the other hand, it is for example possible to read from the terminal a query and execute it, which is prohibited by Teyjus because the correctness of the query cannot be statically enforced.

To illustrate a typical LambdaProlog example, in Table~\ref{type-checker1} we show the code of a type-checker for closed terms of the simply typed lambda-calculus. We use the binary predicate \texttt{app} to encode application, and the unary predicate \texttt{lam} for lambda-abstraction. The latter is to be applied to a meta-level lamdba-abstraction in the spirit of higher-order abstract syntax. For example, the term $\lambda x.xx$ is encoded as \texttt{lam x \ app x x}. Note that, in the concrete syntax, parentheses around lambda-abstractions are not necessary in LambdaProlog when the abstraction is the last argument of an application. I.e. \texttt{lam x \ app x x} is to be read as \texttt{lam (x \ app x x)}.

Observe that the code of the type-checker is really minimal and in one-to-one correspondence with the two derivation rules one writes usually on paper. However, there are some differences as well. In particular, the typing judgement \texttt{term T TY} (``\texttt{T}'' is a term of type ``\texttt{TY}'') does not mention any context $\Gamma$. Instead, in the rule for lambda-abstraction, the hypothesis that the fresh variable \texttt{x} has type \texttt{A} is directly assumed and put temporarily in the program code using logical implication \texttt{=>}.
For example, the query \texttt{term (lam y \ app y y) TY} will match the second
clause and trigger the new query \texttt{term (app x x) B} after having istantiated \texttt{TY} with \texttt{arr A B} where \texttt{x} is fresh (because introduced by \texttt{pi}) and it is known to have type \texttt{A}.

Finally, we will use the cut predicate of Prolog \texttt{!} with the same
non-logical semantics. We say that a predicate does not have a logical semantics
when it breaks the commutativity rule of conunction or, equivalently, commutation of the semantics with istantiation.

\begin{table}[t]
\begin{Verbatim}[numbers=left,numbersep=1pt,frame=leftline]
term (app M N) B :- term M (arr A B), term N A.
term (lam F) (arr A B) :- pi x\ term x A => term (F x) B.
\end{Verbatim}
\caption{\label{type-checker1}A type-checker for simply typed lambda calculus.}
\end{table}

\section{HOL in a nutshell and its implementation in ML}

\section{The kernel in LamdbaProlog}

\section{Towards a Constrained Programming Extension of LambdaProlog}

\section{Parsing and Pretty Printing}

\section{Tactics and Tacticals}

\section{Definitional Mechanisms}

\section{Conclusions and Future Work}

\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}


\end{document}
